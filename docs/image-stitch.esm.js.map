{"version":3,"file":"image-stitch.esm.js","sources":["image-stitch.esm.js"],"sourcesContent":["/**\n * image-stitch bundle\n * Generated on 2025-10-30T17:39:00.156Z\n */\n// ===== dist/esm/utils.js =====\n/**\n * CRC32 lookup table for PNG chunk validation\n */\nconst CRC_TABLE = new Uint32Array(256);\n// Initialize CRC table\nfor (let n = 0; n < 256; n++) {\n    let c = n;\n    for (let k = 0; k < 8; k++) {\n        c = (c & 1) ? 0xedb88320 ^ (c >>> 1) : c >>> 1;\n    }\n    CRC_TABLE[n] = c;\n}\n/**\n * Calculate CRC32 checksum for PNG chunk\n */\nfunction crc32Internal(data, start = 0, length = data.length) {\n    let crc = 0xffffffff;\n    for (let i = start; i < start + length; i++) {\n        crc = CRC_TABLE[(crc ^ data[i]) & 0xff] ^ (crc >>> 8);\n    }\n    return (crc ^ 0xffffffff) >>> 0;\n}\n\n/**\n * Read a 32-bit big-endian unsigned integer\n */\nfunction readUInt32BE(buffer, offset) {\n    return ((buffer[offset] << 24) |\n        (buffer[offset + 1] << 16) |\n        (buffer[offset + 2] << 8) |\n        buffer[offset + 3]) >>> 0;\n}\n/**\n * Write a 32-bit big-endian unsigned integer\n */\nfunction writeUInt32BE(buffer, value, offset) {\n    buffer[offset] = (value >>> 24) & 0xff;\n    buffer[offset + 1] = (value >>> 16) & 0xff;\n    buffer[offset + 2] = (value >>> 8) & 0xff;\n    buffer[offset + 3] = value & 0xff;\n}\n/**\n * Convert string to Uint8Array (ASCII)\n */\nfunction stringToBytes(str) {\n    const bytes = new Uint8Array(str.length);\n    for (let i = 0; i < str.length; i++) {\n        bytes[i] = str.charCodeAt(i);\n    }\n    return bytes;\n}\n/**\n * Convert Uint8Array to string (ASCII)\n */\nfunction bytesToString(bytes, start = 0, length = bytes.length) {\n    let str = '';\n    for (let i = start; i < start + length; i++) {\n        str += String.fromCharCode(bytes[i]);\n    }\n    return str;\n}\n/**\n * PNG file signature\n */\nconst PNG_SIGNATURE = new Uint8Array([137, 80, 78, 71, 13, 10, 26, 10]);\n/**\n * Verify PNG signature\n */\nfunction isPngSignature(data) {\n    if (data.length < 8)\n        return false;\n    for (let i = 0; i < 8; i++) {\n        if (data[i] !== PNG_SIGNATURE[i])\n            return false;\n    }\n    return true;\n}\n/**\n * Get number of samples per pixel for a color type\n */\nfunction getSamplesPerPixel(colorType) {\n    switch (colorType) {\n        case 0: return 1; // Grayscale\n        case 2: return 3; // RGB\n        case 3: return 1; // Palette\n        case 4: return 2; // Grayscale + Alpha\n        case 6: return 4; // RGBA\n        default: throw new Error(`Unknown color type: ${colorType}`);\n    }\n}\n\n// ===== dist/esm/png-filter.js =====\n/**\n * PNG Filter Types\n * Each scanline in a PNG is preceded by a filter type byte\n */\nvar FilterType;\n(function (FilterType) {\n    FilterType[FilterType[\"None\"] = 0] = \"None\";\n    FilterType[FilterType[\"Sub\"] = 1] = \"Sub\";\n    FilterType[FilterType[\"Up\"] = 2] = \"Up\";\n    FilterType[FilterType[\"Average\"] = 3] = \"Average\";\n    FilterType[FilterType[\"Paeth\"] = 4] = \"Paeth\";\n})(FilterType || (FilterType = {}));\n/**\n * Paeth predictor function used in PNG filtering\n */\nfunction paethPredictor(a, b, c) {\n    const p = a + b - c;\n    const pa = Math.abs(p - a);\n    const pb = Math.abs(p - b);\n    const pc = Math.abs(p - c);\n    if (pa <= pb && pa <= pc)\n        return a;\n    if (pb <= pc)\n        return b;\n    return c;\n}\n/**\n * Unfilter a PNG scanline\n * @param filterType The filter type byte\n * @param scanline The filtered scanline (without filter type byte)\n * @param previousLine The previous unfiltered scanline (or null for first line)\n * @param bytesPerPixel Number of bytes per pixel\n */\nfunction unfilterScanline(filterType, scanline, previousLine, bytesPerPixel) {\n    const result = new Uint8Array(scanline.length);\n    switch (filterType) {\n        case FilterType.None:\n            result.set(scanline);\n            break;\n        case FilterType.Sub:\n            for (let i = 0; i < scanline.length; i++) {\n                const left = i >= bytesPerPixel ? result[i - bytesPerPixel] : 0;\n                result[i] = (scanline[i] + left) & 0xff;\n            }\n            break;\n        case FilterType.Up:\n            for (let i = 0; i < scanline.length; i++) {\n                const up = previousLine ? previousLine[i] : 0;\n                result[i] = (scanline[i] + up) & 0xff;\n            }\n            break;\n        case FilterType.Average:\n            for (let i = 0; i < scanline.length; i++) {\n                const left = i >= bytesPerPixel ? result[i - bytesPerPixel] : 0;\n                const up = previousLine ? previousLine[i] : 0;\n                result[i] = (scanline[i] + Math.floor((left + up) / 2)) & 0xff;\n            }\n            break;\n        case FilterType.Paeth:\n            for (let i = 0; i < scanline.length; i++) {\n                const left = i >= bytesPerPixel ? result[i - bytesPerPixel] : 0;\n                const up = previousLine ? previousLine[i] : 0;\n                const upLeft = previousLine && i >= bytesPerPixel ? previousLine[i - bytesPerPixel] : 0;\n                result[i] = (scanline[i] + paethPredictor(left, up, upLeft)) & 0xff;\n            }\n            break;\n        default:\n            throw new Error(`Unknown filter type: ${filterType}`);\n    }\n    return result;\n}\n/**\n * Apply Sub filter to a scanline\n */\nfunction filterSub(scanline, bytesPerPixel) {\n    const result = new Uint8Array(scanline.length);\n    for (let i = 0; i < scanline.length; i++) {\n        const left = i >= bytesPerPixel ? scanline[i - bytesPerPixel] : 0;\n        result[i] = (scanline[i] - left) & 0xff;\n    }\n    return result;\n}\n/**\n * Apply Up filter to a scanline\n */\nfunction filterUp(scanline, previousLine) {\n    const result = new Uint8Array(scanline.length);\n    for (let i = 0; i < scanline.length; i++) {\n        const up = previousLine ? previousLine[i] : 0;\n        result[i] = (scanline[i] - up) & 0xff;\n    }\n    return result;\n}\n/**\n * Apply Average filter to a scanline\n */\nfunction filterAverage(scanline, previousLine, bytesPerPixel) {\n    const result = new Uint8Array(scanline.length);\n    for (let i = 0; i < scanline.length; i++) {\n        const left = i >= bytesPerPixel ? scanline[i - bytesPerPixel] : 0;\n        const up = previousLine ? previousLine[i] : 0;\n        result[i] = (scanline[i] - Math.floor((left + up) / 2)) & 0xff;\n    }\n    return result;\n}\n/**\n * Apply Paeth filter to a scanline\n */\nfunction filterPaeth(scanline, previousLine, bytesPerPixel) {\n    const result = new Uint8Array(scanline.length);\n    for (let i = 0; i < scanline.length; i++) {\n        const left = i >= bytesPerPixel ? scanline[i - bytesPerPixel] : 0;\n        const up = previousLine ? previousLine[i] : 0;\n        const upLeft = previousLine && i >= bytesPerPixel ? previousLine[i - bytesPerPixel] : 0;\n        result[i] = (scanline[i] - paethPredictor(left, up, upLeft)) & 0xff;\n    }\n    return result;\n}\n/**\n * Choose the best filter for a scanline and apply it\n * Uses a simple heuristic: choose the filter that produces the smallest sum of absolute values\n */\nfunction filterScanline(scanline, previousLine, bytesPerPixel) {\n    // Try different filters and choose the best one\n    const candidates = [\n        { type: FilterType.None, data: scanline },\n        { type: FilterType.Sub, data: filterSub(scanline, bytesPerPixel) },\n        { type: FilterType.Up, data: filterUp(scanline, previousLine) },\n        { type: FilterType.Average, data: filterAverage(scanline, previousLine, bytesPerPixel) },\n        { type: FilterType.Paeth, data: filterPaeth(scanline, previousLine, bytesPerPixel) }\n    ];\n    // Calculate sum of absolute values for each filter\n    let bestFilter = candidates[0];\n    let bestSum = Infinity;\n    for (const candidate of candidates) {\n        let sum = 0;\n        for (let i = 0; i < candidate.data.length; i++) {\n            // Treat bytes as signed for better filter selection\n            const signed = candidate.data[i] > 127 ? candidate.data[i] - 256 : candidate.data[i];\n            sum += Math.abs(signed);\n        }\n        if (sum < bestSum) {\n            bestSum = sum;\n            bestFilter = candidate;\n        }\n    }\n    return { filterType: bestFilter.type, filtered: bestFilter.data };\n}\n/**\n * Calculate bytes per pixel from PNG header information\n */\nfunction getBytesPerPixel(bitDepth, colorType) {\n    // ColorType: 0=grayscale, 2=RGB, 3=palette, 4=grayscale+alpha, 6=RGBA\n    let samplesPerPixel = 1;\n    switch (colorType) {\n        case 0: // Grayscale\n            samplesPerPixel = 1;\n            break;\n        case 2: // RGB\n            samplesPerPixel = 3;\n            break;\n        case 3: // Palette\n            samplesPerPixel = 1;\n            break;\n        case 4: // Grayscale + Alpha\n            samplesPerPixel = 2;\n            break;\n        case 6: // RGBA\n            samplesPerPixel = 4;\n            break;\n        default:\n            throw new Error(`Unknown color type: ${colorType}`);\n    }\n    return Math.ceil((samplesPerPixel * bitDepth) / 8);\n}\n\n// ===== dist/esm/png-writer.js =====\n\n/**\n * Create a PNG chunk\n */\nfunction createChunk(type, data) {\n    const typeBytes = stringToBytes(type);\n    if (typeBytes.length !== 4) {\n        throw new Error('Chunk type must be exactly 4 characters');\n    }\n    // Calculate CRC of type + data\n    const crcData = new Uint8Array(4 + data.length);\n    crcData.set(typeBytes, 0);\n    crcData.set(data, 4);\n    const crc = crc32(crcData);\n    return {\n        length: data.length,\n        type,\n        data,\n        crc\n    };\n}\n/**\n * Serialize a chunk to bytes\n */\nfunction serializeChunk(chunk) {\n    const buffer = new Uint8Array(12 + chunk.length);\n    let offset = 0;\n    // Write length\n    writeUInt32BE(buffer, chunk.length, offset);\n    offset += 4;\n    // Write type\n    const typeBytes = stringToBytes(chunk.type);\n    buffer.set(typeBytes, offset);\n    offset += 4;\n    // Write data\n    buffer.set(chunk.data, offset);\n    offset += chunk.length;\n    // Write CRC\n    writeUInt32BE(buffer, chunk.crc, offset);\n    return buffer;\n}\n/**\n * Create IHDR chunk from header information\n */\nfunction createIHDR(header) {\n    const data = new Uint8Array(13);\n    writeUInt32BE(data, header.width, 0);\n    writeUInt32BE(data, header.height, 4);\n    data[8] = header.bitDepth;\n    data[9] = header.colorType;\n    data[10] = header.compressionMethod;\n    data[11] = header.filterMethod;\n    data[12] = header.interlaceMethod;\n    return createChunk('IHDR', data);\n}\n/**\n * Create IEND chunk\n */\nfunction createIEND() {\n    return createChunk('IEND', new Uint8Array(0));\n}\n/**\n * Build a complete PNG file from chunks\n */\nfunction buildPng(chunks) {\n    // Calculate total size\n    let totalSize = 8; // Signature\n    for (const chunk of chunks) {\n        totalSize += 12 + chunk.length; // length(4) + type(4) + data + crc(4)\n    }\n    const buffer = new Uint8Array(totalSize);\n    let offset = 0;\n    // Write signature\n    buffer.set(PNG_SIGNATURE, offset);\n    offset += 8;\n    // Write chunks\n    for (const chunk of chunks) {\n        const chunkBytes = serializeChunk(chunk);\n        buffer.set(chunkBytes, offset);\n        offset += chunkBytes.length;\n    }\n    return buffer;\n}\n\n// ===== dist/esm/png-parser.js =====\n\n/**\n * Parse PNG file and extract chunks\n */\nclass PngParser {\n    data;\n    offset;\n    constructor(data) {\n        this.data = data;\n        this.offset = 0;\n        if (!isPngSignature(data)) {\n            throw new Error('Invalid PNG signature');\n        }\n        this.offset = 8; // Skip signature\n    }\n    /**\n     * Read the next chunk from the PNG file\n     */\n    readChunk() {\n        if (this.offset >= this.data.length) {\n            return null;\n        }\n        // Need at least 12 bytes for chunk structure (length + type + crc)\n        if (this.offset + 12 > this.data.length) {\n            throw new Error('Incomplete PNG chunk');\n        }\n        const length = readUInt32BE(this.data, this.offset);\n        this.offset += 4;\n        const typeBytes = this.data.slice(this.offset, this.offset + 4);\n        const type = bytesToString(typeBytes);\n        this.offset += 4;\n        if (this.offset + length + 4 > this.data.length) {\n            throw new Error('Incomplete PNG chunk data');\n        }\n        const data = this.data.slice(this.offset, this.offset + length);\n        this.offset += length;\n        const crc = readUInt32BE(this.data, this.offset);\n        this.offset += 4;\n        // Verify CRC (includes type + data)\n        const crcData = new Uint8Array(4 + length);\n        crcData.set(typeBytes, 0);\n        crcData.set(data, 4);\n        const calculatedCrc = crc32(crcData);\n        if (calculatedCrc !== crc) {\n            throw new Error(`CRC mismatch for chunk ${type}`);\n        }\n        return { length, type, data, crc };\n    }\n    /**\n     * Read all chunks from the PNG file\n     */\n    readAllChunks() {\n        const chunks = [];\n        let chunk;\n        while ((chunk = this.readChunk()) !== null) {\n            chunks.push(chunk);\n        }\n        return chunks;\n    }\n    /**\n     * Parse IHDR chunk to get image header information\n     */\n    static parseHeader(chunk) {\n        if (chunk.type !== 'IHDR') {\n            throw new Error('Not an IHDR chunk');\n        }\n        if (chunk.data.length !== 13) {\n            throw new Error('Invalid IHDR chunk length');\n        }\n        return {\n            width: readUInt32BE(chunk.data, 0),\n            height: readUInt32BE(chunk.data, 4),\n            bitDepth: chunk.data[8],\n            colorType: chunk.data[9],\n            compressionMethod: chunk.data[10],\n            filterMethod: chunk.data[11],\n            interlaceMethod: chunk.data[12]\n        };\n    }\n    /**\n     * Get PNG header from file\n     */\n    getHeader() {\n        // Reset to start of chunks\n        const savedOffset = this.offset;\n        this.offset = 8;\n        const firstChunk = this.readChunk();\n        if (!firstChunk || firstChunk.type !== 'IHDR') {\n            throw new Error('First chunk must be IHDR');\n        }\n        const header = PngParser.parseHeader(firstChunk);\n        // Restore offset\n        this.offset = savedOffset;\n        return header;\n    }\n}\n/**\n * Parse PNG file and return header information\n */\nfunction parsePngHeader(data) {\n    const parser = new PngParser(data);\n    return parser.getHeader();\n}\n/**\n * Parse PNG file and return all chunks\n */\nfunction parsePngChunks(data) {\n    const parser = new PngParser(data);\n    return parser.readAllChunks();\n}\n\n// ===== dist/esm/png-input-adapter.js =====\nconst open = async () => { throw new Error('File system access is not available in this environment'); };\nconst readFileSync = () => { throw new Error('File system access is not available in this environment'); };\n/**\n * PNG Input Adapter Architecture\n *\n * Provides a streaming interface for various PNG input sources.\n * Supports file-based, memory-based, and future extensible input types\n * (canvas, different formats, generated images, etc.)\n */\n\n\n\n\n\nasync function* decodeScanlinesFromCompressedData(compressedData, header) {\n    const bytesPerPixel = getBytesPerPixel(header.bitDepth, header.colorType);\n    const scanlineLength = Math.ceil((header.width * header.bitDepth * getSamplesPerPixel(header.colorType)) / 8);\n    const bytesPerLine = 1 + scanlineLength;\n    let previousScanline = null;\n    let buffer = new Uint8Array(0);\n    let processedLines = 0;\n    const sourceBuffer = compressedData.byteOffset === 0 && compressedData.byteLength === compressedData.buffer.byteLength\n        ? compressedData.buffer\n        : compressedData.buffer.slice(compressedData.byteOffset, compressedData.byteOffset + compressedData.byteLength);\n    const normalizedBuffer = sourceBuffer instanceof ArrayBuffer ? sourceBuffer : new Uint8Array(sourceBuffer).slice().buffer;\n    const decompressedStream = new Blob([normalizedBuffer]).stream().pipeThrough(new DecompressionStream('deflate'));\n    const reader = decompressedStream.getReader();\n    try {\n        while (processedLines < header.height) {\n            const { value, done } = await reader.read();\n            if (done) {\n                break;\n            }\n            if (!value || value.length === 0) {\n                continue;\n            }\n            const merged = new Uint8Array(buffer.length + value.length);\n            merged.set(buffer, 0);\n            merged.set(value, buffer.length);\n            buffer = merged;\n            while (buffer.length >= bytesPerLine && processedLines < header.height) {\n                const filterType = buffer[0];\n                const filtered = buffer.subarray(1, 1 + scanlineLength);\n                buffer = buffer.subarray(bytesPerLine);\n                const unfiltered = unfilterScanline(filterType, filtered, previousScanline, bytesPerPixel);\n                previousScanline = unfiltered;\n                processedLines++;\n                yield unfiltered;\n            }\n        }\n    }\n    finally {\n        reader.releaseLock();\n    }\n    while (buffer.length >= bytesPerLine && processedLines < header.height) {\n        const filterType = buffer[0];\n        const filtered = buffer.subarray(1, 1 + scanlineLength);\n        buffer = buffer.subarray(bytesPerLine);\n        const unfiltered = unfilterScanline(filterType, filtered, previousScanline, bytesPerPixel);\n        previousScanline = unfiltered;\n        processedLines++;\n        yield unfiltered;\n    }\n    if (processedLines !== header.height) {\n        throw new Error(`Expected ${header.height} scanlines, decoded ${processedLines}`);\n    }\n    if (buffer.length > 0) {\n        const hasResidualData = buffer.some((value) => value !== 0);\n        if (hasResidualData) {\n            throw new Error(`Unexpected remaining decompressed data (${buffer.length} bytes)`);\n        }\n    }\n}\n/**\n * Adapter for file-based PNG inputs\n * Streams data directly from disk with minimal memory usage\n */\nclass FileInputAdapter {\n    fileHandle = null;\n    header = null;\n    filePath;\n    constructor(filePath) {\n        this.filePath = filePath;\n    }\n    async getHeader() {\n        if (this.header) {\n            return this.header;\n        }\n        // Read just enough to parse the header (typically < 1KB)\n        const data = readFileSync(this.filePath);\n        this.header = parsePngHeader(data);\n        return this.header;\n    }\n    async *scanlines() {\n        const header = await this.getHeader();\n        // Open file for streaming\n        this.fileHandle = await open(this.filePath, 'r');\n        try {\n            // Find and read IDAT chunks\n            const idatData = await this.extractIdatData();\n            const compressedView = new Uint8Array(idatData.buffer, idatData.byteOffset, idatData.byteLength);\n            for await (const scanline of decodeScanlinesFromCompressedData(compressedView, header)) {\n                yield scanline;\n            }\n        }\n        finally {\n            // Ensure file handle is closed even if iteration stops early\n            if (this.fileHandle) {\n                await this.fileHandle.close();\n                this.fileHandle = null;\n            }\n        }\n    }\n    async close() {\n        if (this.fileHandle) {\n            await this.fileHandle.close();\n            this.fileHandle = null;\n        }\n    }\n    async extractIdatData() {\n        if (!this.fileHandle) {\n            throw new Error('File not opened');\n        }\n        let position = 8; // Skip PNG signature\n        const idatChunks = [];\n        // Find all IDAT chunks\n        while (true) {\n            const lengthBuffer = Buffer.alloc(4);\n            await this.fileHandle.read(lengthBuffer, 0, 4, position);\n            const chunkLength = readUInt32BE(new Uint8Array(lengthBuffer), 0);\n            position += 4;\n            const typeBuffer = Buffer.alloc(4);\n            await this.fileHandle.read(typeBuffer, 0, 4, position);\n            const chunkType = bytesToString(new Uint8Array(typeBuffer));\n            position += 4;\n            if (chunkType === 'IDAT') {\n                idatChunks.push({ offset: position, length: chunkLength });\n            }\n            position += chunkLength + 4; // Skip data + CRC\n            if (chunkType === 'IEND') {\n                break;\n            }\n        }\n        // Read and concatenate all IDAT data\n        let totalIdatLength = 0;\n        for (const chunk of idatChunks) {\n            totalIdatLength += chunk.length;\n        }\n        const idatData = Buffer.alloc(totalIdatLength);\n        let offset = 0;\n        for (const chunk of idatChunks) {\n            await this.fileHandle.read(idatData, offset, chunk.length, chunk.offset);\n            offset += chunk.length;\n        }\n        return idatData;\n    }\n}\n/**\n * Adapter for Uint8Array (in-memory) PNG inputs\n * Efficient for already-loaded images\n */\nclass Uint8ArrayInputAdapter {\n    header = null;\n    data;\n    constructor(data) {\n        this.data = data;\n    }\n    async getHeader() {\n        if (this.header) {\n            return this.header;\n        }\n        this.header = parsePngHeader(this.data);\n        return this.header;\n    }\n    async *scanlines() {\n        const header = await this.getHeader();\n        const chunks = parsePngChunks(this.data);\n        // Find and concatenate IDAT chunks\n        const idatChunks = chunks.filter(chunk => chunk.type === 'IDAT');\n        if (idatChunks.length === 0) {\n            throw new Error('No IDAT chunks found in PNG');\n        }\n        let totalLength = 0;\n        for (const chunk of idatChunks) {\n            totalLength += chunk.data.length;\n        }\n        const compressedData = new Uint8Array(totalLength);\n        let offset = 0;\n        for (const chunk of idatChunks) {\n            compressedData.set(chunk.data, offset);\n            offset += chunk.data.length;\n        }\n        for await (const scanline of decodeScanlinesFromCompressedData(compressedData, header)) {\n            yield scanline;\n        }\n    }\n    async close() {\n        // No resources to clean up for memory-based input\n    }\n}\n/**\n * Factory function to create appropriate adapter for any input type\n * Supports auto-detection of input types\n */\nasync function createInputAdapter(input) {\n    // If already an adapter, return as-is\n    if (typeof input === 'object' && 'getHeader' in input && 'scanlines' in input && 'close' in input) {\n        return input;\n    }\n    // Auto-detect input type\n    if (typeof input === 'string') {\n        return new FileInputAdapter(input);\n    }\n    if (input instanceof Uint8Array) {\n        return new Uint8ArrayInputAdapter(input);\n    }\n    if (input instanceof ArrayBuffer) {\n        return new Uint8ArrayInputAdapter(new Uint8Array(input));\n    }\n    throw new Error('Unsupported input type. Expected string (file path), Uint8Array, ArrayBuffer, or PngInputAdapter');\n}\n/**\n * Create multiple adapters from mixed input types\n */\nasync function createInputAdapters(inputs) {\n    return Promise.all(inputs.map(input => createInputAdapter(input)));\n}\n\n// ===== dist/esm/pixel-ops.js =====\n\n\n/**\n * Copy a rectangular region from one image to another\n */\nfunction copyPixelRegion(src, srcHeader, dst, dstHeader, srcX, srcY, dstX, dstY, width, height) {\n    const bytesPerPixel = getBytesPerPixel(srcHeader.bitDepth, srcHeader.colorType);\n    const srcRowBytes = Math.ceil((srcHeader.width * srcHeader.bitDepth * getSamplesPerPixel(srcHeader.colorType)) / 8);\n    const dstRowBytes = Math.ceil((dstHeader.width * dstHeader.bitDepth * getSamplesPerPixel(dstHeader.colorType)) / 8);\n    const copyBytes = width * bytesPerPixel;\n    for (let y = 0; y < height; y++) {\n        const srcOffset = (srcY + y) * srcRowBytes + srcX * bytesPerPixel;\n        const dstOffset = (dstY + y) * dstRowBytes + dstX * bytesPerPixel;\n        dst.set(src.slice(srcOffset, srcOffset + copyBytes), dstOffset);\n    }\n}\n/**\n * Fill a rectangular region with a solid color\n */\nfunction fillPixelRegion(dst, dstHeader, dstX, dstY, width, height, color) {\n    const bytesPerPixel = getBytesPerPixel(dstHeader.bitDepth, dstHeader.colorType);\n    const dstRowBytes = Math.ceil((dstHeader.width * dstHeader.bitDepth * getSamplesPerPixel(dstHeader.colorType)) / 8);\n    if (color.length !== bytesPerPixel) {\n        throw new Error(`Color must have ${bytesPerPixel} bytes`);\n    }\n    for (let y = 0; y < height; y++) {\n        for (let x = 0; x < width; x++) {\n            const dstOffset = (dstY + y) * dstRowBytes + (dstX + x) * bytesPerPixel;\n            dst.set(color, dstOffset);\n        }\n    }\n}\n/**\n * Create a blank image with all pixels set to a color\n */\nfunction createBlankImage(header, backgroundColor = new Uint8Array([0, 0, 0, 0])) {\n    const bytesPerPixel = getBytesPerPixel(header.bitDepth, header.colorType);\n    const rowBytes = Math.ceil((header.width * header.bitDepth * getSamplesPerPixel(header.colorType)) / 8);\n    const totalBytes = header.height * rowBytes;\n    const data = new Uint8Array(totalBytes);\n    // Fill with background color\n    if (backgroundColor.length !== bytesPerPixel) {\n        // Adjust background color to match format\n        backgroundColor = backgroundColor.slice(0, bytesPerPixel);\n    }\n    for (let i = 0; i < totalBytes; i += bytesPerPixel) {\n        data.set(backgroundColor, i);\n    }\n    return data;\n}\n/**\n * Get transparent color for a given color type and bit depth\n */\nfunction getTransparentColor(colorType, bitDepth) {\n    const bytesPerSample = bitDepth === 16 ? 2 : 1;\n    switch (colorType) {\n        case 0: // Grayscale - black\n            return new Uint8Array(bytesPerSample).fill(0);\n        case 2: // RGB - black\n            return new Uint8Array(3 * bytesPerSample).fill(0);\n        case 4: // Grayscale + Alpha - transparent black\n            if (bitDepth === 16) {\n                return new Uint8Array([0, 0, 0, 0]); // 16-bit: gray=0, alpha=0\n            }\n            return new Uint8Array([0, 0]); // 8-bit: gray=0, alpha=0\n        case 6: // RGBA - transparent black\n            if (bitDepth === 16) {\n                return new Uint8Array([0, 0, 0, 0, 0, 0, 0, 0]); // R=0, G=0, B=0, A=0\n            }\n            return new Uint8Array([0, 0, 0, 0]); // R=0, G=0, B=0, A=0\n        default:\n            throw new Error(`Unsupported color type: ${colorType}`);\n    }\n}\n/**\n * Determine the best common format for a set of PNG headers\n * Returns the bit depth and color type that can represent all images\n */\nfunction determineCommonFormat(headers) {\n    // Find the maximum bit depth\n    let maxBitDepth = 8;\n    for (const header of headers) {\n        // Track bit depth (anything > 8 means we need 16-bit)\n        if (header.bitDepth === 16) {\n            maxBitDepth = 16;\n        }\n    }\n    // Always use RGBA as target format for maximum compatibility\n    // This simplifies the conversion logic\n    return { bitDepth: maxBitDepth, colorType: 6 };\n}\n/**\n * Scale a sample value from one bit depth to another\n */\nfunction scaleSample(value, fromBits, toBits) {\n    if (fromBits === toBits)\n        return value;\n    // Scale up: multiply by the ratio of max values\n    if (fromBits < toBits) {\n        const fromMax = (1 << fromBits) - 1;\n        const toMax = (1 << toBits) - 1;\n        return Math.round((value * toMax) / fromMax);\n    }\n    // Scale down: divide by the ratio\n    const fromMax = (1 << fromBits) - 1;\n    const toMax = (1 << toBits) - 1;\n    return Math.round((value * toMax) / fromMax);\n}\n/**\n * Convert pixel data from one format to another\n * Converts any PNG format to RGBA (8-bit or 16-bit)\n */\nfunction convertPixelFormat(srcData, srcHeader, targetBitDepth, targetColorType) {\n    // If already in target format, return as-is\n    if (srcHeader.bitDepth === targetBitDepth && srcHeader.colorType === targetColorType) {\n        return { data: srcData, header: srcHeader };\n    }\n    // Only support converting to RGBA\n    if (targetColorType !== 6) {\n        throw new Error('Only conversion to RGBA (color type 6) is supported');\n    }\n    const width = srcHeader.width;\n    const height = srcHeader.height;\n    const srcBitDepth = srcHeader.bitDepth;\n    const srcColorType = srcHeader.colorType;\n    // Calculate output size\n    const targetBytesPerPixel = targetBitDepth === 16 ? 8 : 4; // RGBA\n    const targetRowBytes = width * targetBytesPerPixel;\n    const targetData = new Uint8Array(height * targetRowBytes);\n    // Process each pixel\n    for (let y = 0; y < height; y++) {\n        for (let x = 0; x < width; x++) {\n            let r = 0, g = 0, b = 0, a = 255; // Default to opaque\n            // Read source pixel based on format\n            if (srcColorType === 0) {\n                // Grayscale\n                const srcRowBytes = Math.ceil((width * srcBitDepth) / 8);\n                if (srcBitDepth === 16) {\n                    const offset = y * srcRowBytes + x * 2;\n                    const gray = (srcData[offset] << 8) | srcData[offset + 1];\n                    r = g = b = scaleSample(gray, 16, targetBitDepth);\n                }\n                else if (srcBitDepth === 8) {\n                    const offset = y * srcRowBytes + x;\n                    const gray = srcData[offset];\n                    r = g = b = scaleSample(gray, 8, targetBitDepth);\n                }\n                else {\n                    // Sub-byte bit depths (1, 2, 4)\n                    const srcRowBytes = Math.ceil((width * srcBitDepth) / 8);\n                    const byteOffset = y * srcRowBytes + Math.floor((x * srcBitDepth) / 8);\n                    const bitOffset = (x * srcBitDepth) % 8;\n                    const mask = (1 << srcBitDepth) - 1;\n                    const gray = (srcData[byteOffset] >> (8 - bitOffset - srcBitDepth)) & mask;\n                    r = g = b = scaleSample(gray, srcBitDepth, targetBitDepth);\n                }\n                a = (targetBitDepth === 16) ? 0xFFFF : 0xFF; // Fully opaque\n            }\n            else if (srcColorType === 2) {\n                // RGB\n                const srcBytesPerPixel = (srcBitDepth === 16) ? 6 : 3;\n                const srcRowBytes = width * srcBytesPerPixel;\n                const offset = y * srcRowBytes + x * srcBytesPerPixel;\n                if (srcBitDepth === 16) {\n                    r = ((srcData[offset] << 8) | srcData[offset + 1]);\n                    g = ((srcData[offset + 2] << 8) | srcData[offset + 3]);\n                    b = ((srcData[offset + 4] << 8) | srcData[offset + 5]);\n                    if (targetBitDepth === 8) {\n                        r = scaleSample(r, 16, 8);\n                        g = scaleSample(g, 16, 8);\n                        b = scaleSample(b, 16, 8);\n                    }\n                }\n                else {\n                    r = srcData[offset];\n                    g = srcData[offset + 1];\n                    b = srcData[offset + 2];\n                    if (targetBitDepth === 16) {\n                        r = scaleSample(r, 8, 16);\n                        g = scaleSample(g, 8, 16);\n                        b = scaleSample(b, 8, 16);\n                    }\n                }\n                a = (targetBitDepth === 16) ? 0xFFFF : 0xFF; // Fully opaque\n            }\n            else if (srcColorType === 4) {\n                // Grayscale + Alpha\n                const srcBytesPerPixel = (srcBitDepth === 16) ? 4 : 2;\n                const srcRowBytes = width * srcBytesPerPixel;\n                const offset = y * srcRowBytes + x * srcBytesPerPixel;\n                if (srcBitDepth === 16) {\n                    const gray = (srcData[offset] << 8) | srcData[offset + 1];\n                    r = g = b = (targetBitDepth === 16) ? gray : scaleSample(gray, 16, 8);\n                    a = (srcData[offset + 2] << 8) | srcData[offset + 3];\n                    if (targetBitDepth === 8) {\n                        a = scaleSample(a, 16, 8);\n                    }\n                }\n                else {\n                    r = g = b = (targetBitDepth === 16) ? scaleSample(srcData[offset], 8, 16) : srcData[offset];\n                    a = (targetBitDepth === 16) ? scaleSample(srcData[offset + 1], 8, 16) : srcData[offset + 1];\n                }\n            }\n            else if (srcColorType === 6) {\n                // RGBA\n                const srcBytesPerPixel = (srcBitDepth === 16) ? 8 : 4;\n                const srcRowBytes = width * srcBytesPerPixel;\n                const offset = y * srcRowBytes + x * srcBytesPerPixel;\n                if (srcBitDepth === 16) {\n                    r = (srcData[offset] << 8) | srcData[offset + 1];\n                    g = (srcData[offset + 2] << 8) | srcData[offset + 3];\n                    b = (srcData[offset + 4] << 8) | srcData[offset + 5];\n                    a = (srcData[offset + 6] << 8) | srcData[offset + 7];\n                    if (targetBitDepth === 8) {\n                        r = scaleSample(r, 16, 8);\n                        g = scaleSample(g, 16, 8);\n                        b = scaleSample(b, 16, 8);\n                        a = scaleSample(a, 16, 8);\n                    }\n                }\n                else {\n                    r = srcData[offset];\n                    g = srcData[offset + 1];\n                    b = srcData[offset + 2];\n                    a = srcData[offset + 3];\n                    if (targetBitDepth === 16) {\n                        r = scaleSample(r, 8, 16);\n                        g = scaleSample(g, 8, 16);\n                        b = scaleSample(b, 8, 16);\n                        a = scaleSample(a, 8, 16);\n                    }\n                }\n            }\n            else {\n                throw new Error(`Unsupported source color type: ${srcColorType}`);\n            }\n            // Write target pixel (RGBA)\n            const targetOffset = y * targetRowBytes + x * targetBytesPerPixel;\n            if (targetBitDepth === 16) {\n                targetData[targetOffset] = (r >> 8) & 0xFF;\n                targetData[targetOffset + 1] = r & 0xFF;\n                targetData[targetOffset + 2] = (g >> 8) & 0xFF;\n                targetData[targetOffset + 3] = g & 0xFF;\n                targetData[targetOffset + 4] = (b >> 8) & 0xFF;\n                targetData[targetOffset + 5] = b & 0xFF;\n                targetData[targetOffset + 6] = (a >> 8) & 0xFF;\n                targetData[targetOffset + 7] = a & 0xFF;\n            }\n            else {\n                targetData[targetOffset] = r;\n                targetData[targetOffset + 1] = g;\n                targetData[targetOffset + 2] = b;\n                targetData[targetOffset + 3] = a;\n            }\n        }\n    }\n    // Create new header with target format\n    const targetHeader = {\n        ...srcHeader,\n        bitDepth: targetBitDepth,\n        colorType: targetColorType\n    };\n    return { data: targetData, header: targetHeader };\n}\n/**\n * Convert a single scanline from one format to another\n * This is optimized for streaming - converts one row at a time\n */\nfunction convertScanline(srcScanline, width, srcBitDepth, srcColorType, targetBitDepth, targetColorType) {\n    // If already in target format, return as-is\n    if (srcBitDepth === targetBitDepth && srcColorType === targetColorType) {\n        return srcScanline;\n    }\n    // Only support converting to RGBA\n    if (targetColorType !== 6) {\n        throw new Error('Only conversion to RGBA (color type 6) is supported');\n    }\n    const targetBytesPerPixel = targetBitDepth === 16 ? 8 : 4; // RGBA\n    const targetScanline = new Uint8Array(width * targetBytesPerPixel);\n    // Process each pixel in the scanline\n    for (let x = 0; x < width; x++) {\n        let r = 0, g = 0, b = 0, a = 255; // Default to opaque\n        // Read source pixel based on format\n        if (srcColorType === 0) {\n            // Grayscale\n            if (srcBitDepth === 16) {\n                const offset = x * 2;\n                const gray = (srcScanline[offset] << 8) | srcScanline[offset + 1];\n                r = g = b = scaleSample(gray, 16, targetBitDepth);\n            }\n            else if (srcBitDepth === 8) {\n                const gray = srcScanline[x];\n                r = g = b = scaleSample(gray, 8, targetBitDepth);\n            }\n            else {\n                // Sub-byte bit depths (1, 2, 4)\n                const byteOffset = Math.floor((x * srcBitDepth) / 8);\n                const bitOffset = (x * srcBitDepth) % 8;\n                const mask = (1 << srcBitDepth) - 1;\n                const gray = (srcScanline[byteOffset] >> (8 - bitOffset - srcBitDepth)) & mask;\n                r = g = b = scaleSample(gray, srcBitDepth, targetBitDepth);\n            }\n            a = (targetBitDepth === 16) ? 0xFFFF : 0xFF; // Fully opaque\n        }\n        else if (srcColorType === 2) {\n            // RGB\n            const srcBytesPerPixel = (srcBitDepth === 16) ? 6 : 3;\n            const offset = x * srcBytesPerPixel;\n            if (srcBitDepth === 16) {\n                r = ((srcScanline[offset] << 8) | srcScanline[offset + 1]);\n                g = ((srcScanline[offset + 2] << 8) | srcScanline[offset + 3]);\n                b = ((srcScanline[offset + 4] << 8) | srcScanline[offset + 5]);\n                if (targetBitDepth === 8) {\n                    r = scaleSample(r, 16, 8);\n                    g = scaleSample(g, 16, 8);\n                    b = scaleSample(b, 16, 8);\n                }\n            }\n            else {\n                r = srcScanline[offset];\n                g = srcScanline[offset + 1];\n                b = srcScanline[offset + 2];\n                if (targetBitDepth === 16) {\n                    r = scaleSample(r, 8, 16);\n                    g = scaleSample(g, 8, 16);\n                    b = scaleSample(b, 8, 16);\n                }\n            }\n            a = (targetBitDepth === 16) ? 0xFFFF : 0xFF; // Fully opaque\n        }\n        else if (srcColorType === 4) {\n            // Grayscale + Alpha\n            const srcBytesPerPixel = (srcBitDepth === 16) ? 4 : 2;\n            const offset = x * srcBytesPerPixel;\n            if (srcBitDepth === 16) {\n                const gray = (srcScanline[offset] << 8) | srcScanline[offset + 1];\n                r = g = b = (targetBitDepth === 16) ? gray : scaleSample(gray, 16, 8);\n                a = (srcScanline[offset + 2] << 8) | srcScanline[offset + 3];\n                if (targetBitDepth === 8) {\n                    a = scaleSample(a, 16, 8);\n                }\n            }\n            else {\n                r = g = b = (targetBitDepth === 16) ? scaleSample(srcScanline[offset], 8, 16) : srcScanline[offset];\n                a = (targetBitDepth === 16) ? scaleSample(srcScanline[offset + 1], 8, 16) : srcScanline[offset + 1];\n            }\n        }\n        else if (srcColorType === 6) {\n            // RGBA\n            const srcBytesPerPixel = (srcBitDepth === 16) ? 8 : 4;\n            const offset = x * srcBytesPerPixel;\n            if (srcBitDepth === 16) {\n                r = (srcScanline[offset] << 8) | srcScanline[offset + 1];\n                g = (srcScanline[offset + 2] << 8) | srcScanline[offset + 3];\n                b = (srcScanline[offset + 4] << 8) | srcScanline[offset + 5];\n                a = (srcScanline[offset + 6] << 8) | srcScanline[offset + 7];\n                if (targetBitDepth === 8) {\n                    r = scaleSample(r, 16, 8);\n                    g = scaleSample(g, 16, 8);\n                    b = scaleSample(b, 16, 8);\n                    a = scaleSample(a, 16, 8);\n                }\n            }\n            else {\n                r = srcScanline[offset];\n                g = srcScanline[offset + 1];\n                b = srcScanline[offset + 2];\n                a = srcScanline[offset + 3];\n                if (targetBitDepth === 16) {\n                    r = scaleSample(r, 8, 16);\n                    g = scaleSample(g, 8, 16);\n                    b = scaleSample(b, 8, 16);\n                    a = scaleSample(a, 8, 16);\n                }\n            }\n        }\n        else {\n            throw new Error(`Unsupported source color type: ${srcColorType}`);\n        }\n        // Write target pixel (RGBA)\n        const targetOffset = x * targetBytesPerPixel;\n        if (targetBitDepth === 16) {\n            targetScanline[targetOffset] = (r >> 8) & 0xFF;\n            targetScanline[targetOffset + 1] = r & 0xFF;\n            targetScanline[targetOffset + 2] = (g >> 8) & 0xFF;\n            targetScanline[targetOffset + 3] = g & 0xFF;\n            targetScanline[targetOffset + 4] = (b >> 8) & 0xFF;\n            targetScanline[targetOffset + 5] = b & 0xFF;\n            targetScanline[targetOffset + 6] = (a >> 8) & 0xFF;\n            targetScanline[targetOffset + 7] = a & 0xFF;\n        }\n        else {\n            targetScanline[targetOffset] = r;\n            targetScanline[targetOffset + 1] = g;\n            targetScanline[targetOffset + 2] = b;\n            targetScanline[targetOffset + 3] = a;\n        }\n    }\n    return targetScanline;\n}\n\n// ===== dist/esm/png-concat.js =====\nconst Readable = typeof globalThis !== 'undefined' && globalThis.Readable ? globalThis.Readable : class { constructor() { throw new Error('Readable is not available in this environment'); } };\n/**\n * PNG Concatenation\n *\n * Scanline-by-scanline streaming approach that minimizes memory usage.\n * Processes one output row at a time using the adapter architecture.\n */\n\n\n\n\n\n\n/**\n * Combines multiple scanlines horizontally into one output scanline with variable widths\n */\nfunction combineScanlines(scanlines, widths, bytesPerPixel) {\n    const totalWidth = widths.reduce((sum, w) => sum + w, 0);\n    const output = new Uint8Array(totalWidth * bytesPerPixel);\n    let offset = 0;\n    for (let i = 0; i < scanlines.length; i++) {\n        output.set(scanlines[i], offset);\n        offset += widths[i] * bytesPerPixel;\n    }\n    return output;\n}\n/**\n * Create a transparent scanline of given width\n */\nfunction createTransparentScanline(width, bytesPerPixel, transparentColor) {\n    const scanline = new Uint8Array(width * bytesPerPixel);\n    for (let i = 0; i < width; i++) {\n        scanline.set(transparentColor, i * bytesPerPixel);\n    }\n    return scanline;\n}\n/**\n * Pad a scanline to a target width with transparent pixels\n */\nfunction padScanline(scanline, currentWidth, targetWidth, bytesPerPixel, transparentColor) {\n    if (currentWidth >= targetWidth) {\n        return scanline;\n    }\n    const padded = new Uint8Array(targetWidth * bytesPerPixel);\n    padded.set(scanline, 0);\n    // Fill padding with transparent color\n    for (let i = currentWidth; i < targetWidth; i++) {\n        padded.set(transparentColor, i * bytesPerPixel);\n    }\n    return padded;\n}\n/**\n * Calculate grid layout with variable image sizes\n */\nfunction calculateLayout(headers, options) {\n    const { layout } = options;\n    const numImages = headers.length;\n    let grid = [];\n    if (layout.columns && !layout.height) {\n        const columns = layout.columns;\n        const rows = Math.ceil(numImages / columns);\n        grid = Array.from({ length: rows }, (_, row) => Array.from({ length: columns }, (_, col) => {\n            const idx = row * columns + col;\n            return idx < numImages ? idx : -1;\n        }));\n    }\n    else if (layout.rows && !layout.width) {\n        const rows = layout.rows;\n        const columns = Math.ceil(numImages / rows);\n        grid = Array.from({ length: rows }, (_, row) => Array.from({ length: columns }, (_, col) => {\n            const idx = col * rows + row;\n            return idx < numImages ? idx : -1;\n        }));\n    }\n    else if (layout.width || layout.height) {\n        grid = calculatePixelBasedLayout(headers, layout.width, layout.height, layout.columns, layout.rows);\n    }\n    else {\n        grid = [Array.from({ length: numImages }, (_, i) => i)];\n    }\n    // Calculate max width per column in each row and max height per row\n    const rowHeights = [];\n    const colWidths = [];\n    for (let row = 0; row < grid.length; row++) {\n        let maxHeight = 0;\n        const rowColWidths = [];\n        for (let col = 0; col < grid[row].length; col++) {\n            const imageIdx = grid[row][col];\n            if (imageIdx >= 0) {\n                const header = headers[imageIdx];\n                maxHeight = Math.max(maxHeight, header.height);\n                rowColWidths[col] = Math.max(rowColWidths[col] || 0, header.width);\n            }\n            else {\n                rowColWidths[col] = rowColWidths[col] || 0;\n            }\n        }\n        rowHeights.push(maxHeight);\n        colWidths.push(rowColWidths);\n    }\n    const totalHeight = rowHeights.reduce((sum, h) => sum + h, 0);\n    const totalWidth = Math.max(...colWidths.map(row => row.reduce((sum, w) => sum + w, 0)));\n    return { grid, rowHeights, colWidths, totalWidth, totalHeight };\n}\n/**\n * Calculate layout when pixel-based width/height limits are specified\n */\nfunction calculatePixelBasedLayout(headers, maxWidth, maxHeight, fixedColumns, fixedRows) {\n    const grid = [];\n    let currentRow = [];\n    let currentRowWidth = 0;\n    let currentRowMaxHeight = 0;\n    let totalHeight = 0;\n    for (let i = 0; i < headers.length; i++) {\n        const header = headers[i];\n        const imageWidth = header.width;\n        const imageHeight = header.height;\n        const wouldExceedWidth = maxWidth && (currentRowWidth + imageWidth > maxWidth);\n        const wouldExceedColumns = fixedColumns && (currentRow.length >= fixedColumns);\n        if ((wouldExceedWidth || wouldExceedColumns) && currentRow.length > 0) {\n            // Need to start a new row - check if it would exceed height limit\n            const newRowHeight = imageHeight;\n            const wouldExceedHeight = maxHeight && (totalHeight + currentRowMaxHeight + newRowHeight > maxHeight);\n            if (wouldExceedHeight) {\n                // Can't fit this image - stop here\n                break;\n            }\n            grid.push(currentRow);\n            totalHeight += currentRowMaxHeight;\n            currentRow = [i];\n            currentRowWidth = imageWidth;\n            currentRowMaxHeight = imageHeight;\n        }\n        else {\n            currentRow.push(i);\n            currentRowWidth += imageWidth;\n            currentRowMaxHeight = Math.max(currentRowMaxHeight, imageHeight);\n        }\n        if (fixedRows && grid.length >= fixedRows && currentRow.length === 0) {\n            break;\n        }\n    }\n    if (currentRow.length > 0) {\n        grid.push(currentRow);\n    }\n    return grid;\n}\n/**\n * Streaming PNG concatenation with minimal memory usage\n *\n * This implementation:\n * 1. Pass 1: Reads only headers to validate and plan\n * 2. Pass 2: Processes scanline-by-scanline, streaming output\n *\n * Memory usage: O(rows_in_flight * row_width) instead of O(total_image_size)\n *\n * Supports:\n * - File paths (string)\n * - Uint8Array buffers\n * - ArrayBuffer instances (browser-friendly)\n * - Custom PngInputAdapter implementations\n * - Mixed input types in the same operation\n */\nclass StreamingConcatenator {\n    options;\n    constructor(options) {\n        this.validateOptions(options);\n        this.options = options;\n    }\n    validateOptions(options) {\n        if (!options.inputs || options.inputs.length === 0) {\n            throw new Error('At least one input image is required');\n        }\n        const { layout } = options;\n        if (!layout.columns && !layout.rows && !layout.width && !layout.height) {\n            throw new Error('Must specify layout: columns, rows, width, or height');\n        }\n    }\n    /**\n     * Stream compressed scanline data with TRUE streaming compression\n     *\n     * Uses pako's onData callback for true constant-memory streaming:\n     * - Generates scanlines incrementally\n     * - Batches scanlines (max 10MB) before flush\n     * - Compresses with Z_SYNC_FLUSH (maintains deflate state)\n     * - Yields IDAT chunks immediately via onData callback\n     * - Memory usage: O(batch_size) ~10-20MB regardless of total image size!\n     */\n    async *streamCompressedData(grid, rowHeights, colWidths, totalWidth, headers, iterators, outputHeader, bytesPerPixel, transparentColor) {\n        const { StreamingDeflator } = await import('./streaming-deflate.js');\n        // Create scanline generator\n        const scanlineGenerator = this.generateFilteredScanlines(grid, rowHeights, colWidths, totalWidth, headers, iterators, outputHeader, bytesPerPixel, transparentColor);\n        // Calculate batch size\n        const scanlineSize = totalWidth * bytesPerPixel + 1;\n        const MAX_BATCH_BYTES = 1 * 1024 * 1024; // 1MB\n        const MAX_BATCH_SCANLINES = Math.max(50, Math.floor(MAX_BATCH_BYTES / scanlineSize));\n        // Create deflator\n        const deflator = new StreamingDeflator({\n            level: 6,\n            maxBatchSize: MAX_BATCH_BYTES\n        });\n        // Queue for compressed chunks from onData callback\n        const compressedChunks = [];\n        // Initialize deflator with callback\n        deflator.initialize((compressedData) => {\n            // onData callback - receives compressed chunks immediately!\n            if (compressedData && compressedData.length > 0) {\n                compressedChunks.push(compressedData);\n            }\n        });\n        let scanlineCount = 0;\n        // Process scanlines\n        for await (const scanline of scanlineGenerator) {\n            deflator.push(scanline);\n            scanlineCount++;\n            // Periodic flush for progressive output\n            if (scanlineCount % MAX_BATCH_SCANLINES === 0) {\n                deflator.flush();\n            }\n            // Yield any compressed chunks that were produced\n            while (compressedChunks.length > 0) {\n                const chunk = compressedChunks.shift();\n                yield serializeChunk(createChunk('IDAT', chunk));\n            }\n        }\n        // Finish compression\n        deflator.finish();\n        // Yield remaining compressed chunks\n        while (compressedChunks.length > 0) {\n            const chunk = compressedChunks.shift();\n            yield serializeChunk(createChunk('IDAT', chunk));\n        }\n    }\n    /**\n     * Generate filtered scanlines one at a time\n     */\n    async *generateFilteredScanlines(grid, rowHeights, colWidths, totalWidth, headers, iterators, outputHeader, bytesPerPixel, transparentColor) {\n        let previousOutputScanline = null;\n        // Process each output scanline\n        for (let row = 0; row < grid.length; row++) {\n            const rowHeight = rowHeights[row];\n            const rowColWidths = colWidths[row];\n            // Process each scanline in this row\n            for (let localY = 0; localY < rowHeight; localY++) {\n                const scanlines = [];\n                // Collect scanlines from all images in this row\n                for (let col = 0; col < grid[row].length; col++) {\n                    const imageIdx = grid[row][col];\n                    const colWidth = rowColWidths[col];\n                    if (imageIdx >= 0) {\n                        const imageHeader = headers[imageIdx];\n                        const imageHeight = imageHeader.height;\n                        const imageWidth = imageHeader.width;\n                        if (localY < imageHeight) {\n                            // Read scanline from this image\n                            const { value, done } = await iterators[imageIdx].next();\n                            if (!done) {\n                                // Convert scanline to target format if needed\n                                const convertedScanline = convertScanline(value, imageWidth, imageHeader.bitDepth, imageHeader.colorType, outputHeader.bitDepth, outputHeader.colorType);\n                                // Pad scanline if image is narrower than column\n                                const paddedScanline = padScanline(convertedScanline, imageWidth, colWidth, bytesPerPixel, transparentColor);\n                                scanlines.push(paddedScanline);\n                            }\n                            else {\n                                // Shouldn't happen, but handle gracefully\n                                scanlines.push(createTransparentScanline(colWidth, bytesPerPixel, transparentColor));\n                            }\n                        }\n                        else {\n                            // Below image - use transparent scanline\n                            scanlines.push(createTransparentScanline(colWidth, bytesPerPixel, transparentColor));\n                        }\n                    }\n                    else {\n                        // Empty cell - use transparent scanline\n                        scanlines.push(createTransparentScanline(colWidth, bytesPerPixel, transparentColor));\n                    }\n                }\n                // Combine scanlines horizontally\n                let outputScanline = combineScanlines(scanlines, rowColWidths, bytesPerPixel);\n                // Pad scanline to totalWidth if this row is narrower\n                const rowWidth = rowColWidths.reduce((sum, w) => sum + w, 0);\n                if (rowWidth < totalWidth) {\n                    const paddedScanline = new Uint8Array(totalWidth * bytesPerPixel);\n                    paddedScanline.set(outputScanline, 0);\n                    // Fill the rest with transparent pixels\n                    for (let x = rowWidth; x < totalWidth; x++) {\n                        paddedScanline.set(transparentColor, x * bytesPerPixel);\n                    }\n                    outputScanline = paddedScanline;\n                }\n                // Filter the scanline\n                const { filterType, filtered } = filterScanline(outputScanline, previousOutputScanline, bytesPerPixel);\n                // Create scanline with filter byte\n                const scanlineWithFilter = new Uint8Array(1 + filtered.length);\n                scanlineWithFilter[0] = filterType;\n                scanlineWithFilter.set(filtered, 1);\n                // Yield this scanline - only one at a time!\n                yield scanlineWithFilter;\n                previousOutputScanline = outputScanline;\n            }\n        }\n    }\n    /**\n     * Stream concatenated PNG output scanline-by-scanline\n     */\n    async *stream() {\n        // PASS 1: Create adapters and read headers\n        const adapters = await createInputAdapters(this.options.inputs);\n        const headers = [];\n        try {\n            for (const adapter of adapters) {\n                const header = await adapter.getHeader();\n                headers.push(header);\n            }\n            // Determine common format that can represent all images\n            const { bitDepth: targetBitDepth, colorType: targetColorType } = determineCommonFormat(headers);\n            // Calculate layout with variable image sizes\n            const layout = calculateLayout(headers, this.options);\n            const { grid, rowHeights, colWidths, totalWidth, totalHeight } = layout;\n            // Create output header using common format\n            const outputHeader = {\n                width: totalWidth,\n                height: totalHeight,\n                bitDepth: targetBitDepth,\n                colorType: targetColorType,\n                compressionMethod: 0,\n                filterMethod: 0,\n                interlaceMethod: 0\n            };\n            // Yield PNG signature\n            yield PNG_SIGNATURE;\n            // Yield IHDR\n            yield serializeChunk(createIHDR(outputHeader));\n            // PASS 2: Stream scanlines with true streaming compression\n            // Create iterators for each input\n            const iterators = adapters.map(adapter => adapter.scanlines());\n            const bytesPerPixel = getBytesPerPixel(outputHeader.bitDepth, outputHeader.colorType);\n            const transparentColor = getTransparentColor(outputHeader.colorType, outputHeader.bitDepth);\n            // Use streaming compression - process scanlines one at a time\n            yield* this.streamCompressedData(grid, rowHeights, colWidths, totalWidth, headers, iterators, outputHeader, bytesPerPixel, transparentColor);\n            // Yield IEND\n            yield serializeChunk(createIEND());\n        }\n        finally {\n            // Clean up all adapters\n            for (const adapter of adapters) {\n                await adapter.close();\n            }\n        }\n    }\n    /**\n     * Convert to Node.js Readable stream\n     */\n    toReadableStream() {\n        const generator = this.stream();\n        return new Readable({\n            async read() {\n                try {\n                    const { value, done } = await generator.next();\n                    if (done) {\n                        this.push(null);\n                    }\n                    else {\n                        this.push(Buffer.from(value));\n                    }\n                }\n                catch (error) {\n                    this.destroy(error);\n                }\n            }\n        });\n    }\n}\n/**\n * Concatenate PNGs with streaming (minimal memory usage)\n *\n * This processes images scanline-by-scanline, keeping only a few rows\n * in memory at a time. Ideal for large images.\n *\n * Supports:\n * - File paths (string)\n * - Uint8Array buffers\n * - Mixed input types\n * - Variable image dimensions with automatic padding\n * - All layout options (columns, rows, width, height)\n */\nasync function* concatPngsStreaming(options) {\n    const concatenator = new StreamingConcatenator(options);\n    yield* concatenator.stream();\n}\n/**\n * Get a Readable stream for streaming concatenation\n */\nfunction concatPngsToStream(options) {\n    const concatenator = new StreamingConcatenator(options);\n    return concatenator.toReadableStream();\n}\nfunction concatPngs(options) {\n    return (async () => {\n        if (options.stream) {\n            // User wants streaming output\n            return concatPngsToStream(options);\n        }\n        else {\n            // User wants Uint8Array result - collect chunks from stream\n            const chunks = [];\n            for await (const chunk of concatPngsStreaming(options)) {\n                chunks.push(chunk);\n            }\n            // Combine chunks\n            const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n            const result = new Uint8Array(totalLength);\n            let offset = 0;\n            for (const chunk of chunks) {\n                result.set(chunk, offset);\n                offset += chunk.length;\n            }\n            return result;\n        }\n    })();\n}\n/**\n * Convenience function: concatenate and write to stream\n *\n * @example\n * import { createWriteStream } from 'fs';\n *\n * const stream = await concatPngsToFile({\n *   inputs: ['img1.png', 'img2.png'],\n *   layout: { columns: 2 }\n * });\n * stream.pipe(createWriteStream('output.png'));\n */\nasync function concatPngsToFile(options) {\n    return concatPngs({ ...options, stream: true });\n}\n\n// ===== dist/esm/png-decompress.js =====\n\n\n/**\n * Decompress data using Web Compression Streams API\n * Works in both Node.js (18+) and modern browsers\n */\nasync function decompressData(data) {\n    const stream = new Blob([data]).stream();\n    const decompressedStream = stream.pipeThrough(new DecompressionStream('deflate'));\n    const chunks = [];\n    const reader = decompressedStream.getReader();\n    while (true) {\n        const { value, done } = await reader.read();\n        if (done)\n            break;\n        chunks.push(value);\n    }\n    const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n    const result = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const chunk of chunks) {\n        result.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return result;\n}\n/**\n * Compress data using Web Compression Streams API\n * Works in both Node.js (18+) and modern browsers\n */\nasync function compressData(data) {\n    const stream = new Blob([data]).stream();\n    const compressedStream = stream.pipeThrough(new CompressionStream('deflate'));\n    const chunks = [];\n    const reader = compressedStream.getReader();\n    while (true) {\n        const { value, done } = await reader.read();\n        if (done)\n            break;\n        chunks.push(value);\n    }\n    const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n    const result = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const chunk of chunks) {\n        result.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return result;\n}\n/**\n * Decompress and unfilter PNG image data\n * @param idatChunks Array of IDAT chunks containing compressed image data\n * @param header PNG header information\n * @returns Unfiltered raw pixel data\n */\nasync function decompressImageData(idatChunks, header) {\n    // Concatenate all IDAT chunk data\n    let totalLength = 0;\n    for (const chunk of idatChunks) {\n        if (chunk.type === 'IDAT') {\n            totalLength += chunk.data.length;\n        }\n    }\n    const compressedData = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const chunk of idatChunks) {\n        if (chunk.type === 'IDAT') {\n            compressedData.set(chunk.data, offset);\n            offset += chunk.data.length;\n        }\n    }\n    // Decompress using Web Compression Streams API\n    const decompressed = await decompressData(compressedData);\n    // Unfilter scanlines\n    const bytesPerPixel = getBytesPerPixel(header.bitDepth, header.colorType);\n    const scanlineLength = Math.ceil((header.width * header.bitDepth * getSamplesPerPixel(header.colorType)) / 8);\n    const unfilteredData = new Uint8Array(header.height * scanlineLength);\n    let previousLine = null;\n    let srcOffset = 0;\n    let dstOffset = 0;\n    for (let y = 0; y < header.height; y++) {\n        if (srcOffset >= decompressed.length) {\n            throw new Error('Unexpected end of decompressed data');\n        }\n        const filterType = decompressed[srcOffset++];\n        const scanline = decompressed.slice(srcOffset, srcOffset + scanlineLength);\n        srcOffset += scanlineLength;\n        const unfilteredLine = unfilterScanline(filterType, scanline, previousLine, bytesPerPixel);\n        unfilteredData.set(unfilteredLine, dstOffset);\n        dstOffset += scanlineLength;\n        previousLine = unfilteredLine;\n    }\n    return unfilteredData;\n}\n/**\n * Filter and compress raw pixel data into PNG format\n * @param pixelData Raw unfiltered pixel data\n * @param header PNG header information\n * @returns Compressed IDAT chunk data\n */\nasync function compressImageData(pixelData, header) {\n    const bytesPerPixel = getBytesPerPixel(header.bitDepth, header.colorType);\n    const scanlineLength = Math.ceil((header.width * header.bitDepth * getSamplesPerPixel(header.colorType)) / 8);\n    // Add filter type bytes and filter each scanline\n    const filteredData = new Uint8Array(header.height * (scanlineLength + 1));\n    let srcOffset = 0;\n    let dstOffset = 0;\n    let previousLine = null;\n    for (let y = 0; y < header.height; y++) {\n        const scanline = pixelData.slice(srcOffset, srcOffset + scanlineLength);\n        srcOffset += scanlineLength;\n        const { filterType, filtered } = filterScanline(scanline, previousLine, bytesPerPixel);\n        filteredData[dstOffset++] = filterType;\n        filteredData.set(filtered, dstOffset);\n        dstOffset += filtered.length;\n        previousLine = scanline;\n    }\n    // Compress using Web Compression Streams API\n    const compressed = await compressData(filteredData);\n    return compressed;\n}\n/**\n * Extract pixel data from a PNG file\n */\nasync function extractPixelData(chunks, header) {\n    const idatChunks = chunks.filter(chunk => chunk.type === 'IDAT');\n    if (idatChunks.length === 0) {\n        throw new Error('No IDAT chunks found in PNG');\n    }\n    return await decompressImageData(idatChunks, header);\n}\n\n// ===== dist/esm/types.js =====\n/**\n * PNG color types\n */\nvar ColorType;\n(function (ColorType) {\n    ColorType[ColorType[\"GRAYSCALE\"] = 0] = \"GRAYSCALE\";\n    ColorType[ColorType[\"RGB\"] = 2] = \"RGB\";\n    ColorType[ColorType[\"PALETTE\"] = 3] = \"PALETTE\";\n    ColorType[ColorType[\"GRAYSCALE_ALPHA\"] = 4] = \"GRAYSCALE_ALPHA\";\n    ColorType[ColorType[\"RGBA\"] = 6] = \"RGBA\";\n})(ColorType || (ColorType = {}));\n\nexport { concatPngs, concatPngsToFile, StreamingConcatenator };\nexport { FileInputAdapter, Uint8ArrayInputAdapter, createInputAdapter, createInputAdapters };\nexport { parsePngHeader, parsePngChunks, PngParser };\nexport { createChunk, createIHDR, createIEND, serializeChunk, buildPng };\nexport { decompressImageData, compressImageData, extractPixelData, decompressData };\nexport { unfilterScanline, filterScanline, getBytesPerPixel, FilterType };\nexport { copyPixelRegion, fillPixelRegion, createBlankImage };\nexport { crc32Internal as crc32, readUInt32BE, writeUInt32BE, isPngSignature, PNG_SIGNATURE };\nexport { ColorType };\n"],"names":[],"mappings":"AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA"}